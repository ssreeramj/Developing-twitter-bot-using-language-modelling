{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Algorithm</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> A bigram language model is trained from the corpus. <br />\n",
    "=> Another bigram language model is trained after reversing the sentences from the corpus. <br />\n",
    "=> Given the context word, the model randomly decides to add a prefix or a suffix.<br />\n",
    "=> To add prefix, we generate the word from the language model trained of reversed sentences.<br />\n",
    "=> To add suffix, we generate the word from the language model trained on original sentences.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './corpus.txt'\n",
    "\n",
    "stopwords = ['', '(', ')', '{', '}', '\\\\', '--', ':', '-', \"'s\"]\n",
    "punc = string.punctuation + \"``\" + \"''\" + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r') as f:\n",
    "    data = f.read().lower().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3954021"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(words)\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_rev_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(list(reversed(words)))\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenized_words(data)\n",
    "rev_sents = tokenized_rev_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40992"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [word for sent in sents for word in sent]\n",
    "rev_train_corpus = [word for sent in rev_sents for word in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666665"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_dist(corpus, ngram=1):\n",
    "    if isinstance(corpus, list) and len(corpus)>0:\n",
    "        train_corpus=corpus\n",
    "    elif type(corpus) is str:\n",
    "        train_corpus=nltk.word_tokenize(corpus)\n",
    "    else:\n",
    "        print('Error')\n",
    "        return None\n",
    "    \n",
    "    freq_dist=None\n",
    "    if ngram==1:\n",
    "        freq_dist = nltk.FreqDist(train_corpus) #freq distibution for unigrams\n",
    "    elif ngram==2:\n",
    "        freq_dist = nltk.ConditionalFreqDist(nltk.ngrams(train_corpus, 2))# conditional freq dist for bigrams\n",
    "    elif ngram==3:\n",
    "        trigrams_as_bigrams=[]\n",
    "        trigram =[a for a in ngrams(train_corpus, 3)]\n",
    "        trigrams_as_bigrams.extend([((t[0],t[1]), t[2]) for t in trigram])\n",
    "        freq_dist = nltk.ConditionalFreqDist(trigrams_as_bigrams)# conditional freq dist for trigrams\n",
    "    else:\n",
    "        print('Supported upto trigrams only')\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_2gram = ngram_freq_dist(train_corpus, 2)\n",
    "cfd_2gram_rev = ngram_freq_dist(rev_train_corpus, 2)\n",
    "\n",
    "cpd_2gram = nltk.ConditionalProbDist(cfd_2gram, nltk.MLEProbDist)\n",
    "cpd_2gram_rev = nltk.ConditionalProbDist(cfd_2gram_rev, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_bigram_model_random(cprob_2gram, cprob_2gram_rev, initialword, numwords=15):\n",
    "    text = initialword\n",
    "    suf_word = initialword\n",
    "    pre_word = initialword\n",
    "    for index in range(numwords):\n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                suf_word = cprob_2gram[suf_word].generate()\n",
    "                text = text + \" \" + suf_word\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "        else:\n",
    "            try: \n",
    "                pre_word = cprob_2gram_rev[pre_word].generate()\n",
    "                text = pre_word + ' ' + text\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afford college and national guidelines highlight how education we do right to balance we are underinsured\n",
      "----------------------------------------\n",
      "are with the france attack on our strength and education w… rt thebriefing2016 but somehow changing\n",
      "----------------------------------------\n",
      "the international brotherhood of higher education can take courageous leader we have to tour of health\n",
      "----------------------------------------\n",
      "today we unanimously approved our education should live presidential campaign … when people of eximbankus has\n",
      "----------------------------------------\n",
      "nation as mayors must pursue higher education amp across the battle to go vote … this\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'education'))\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
