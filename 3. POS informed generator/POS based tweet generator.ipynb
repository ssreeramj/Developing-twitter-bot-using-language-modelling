{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../corpus.txt'\n",
    "\n",
    "stopwords = ['', '(', ')', '{', '}', '\\\\', '--', ':', '-', \"'s\"]\n",
    "punc = string.punctuation + \"``\" + \"''\" + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r') as f:\n",
    "    data = f.read().lower().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3954021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(words)\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_rev_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(list(reversed(words)))\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenized_words(data)\n",
    "rev_sents = tokenized_rev_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [word for sent in sents for word in sent]\n",
    "rev_train_corpus = [word for sent in rev_sents for word in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666665"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_dist(corpus, ngram=1):\n",
    "    if isinstance(corpus, list) and len(corpus)>0:\n",
    "        train_corpus=corpus\n",
    "    elif type(corpus) is str:\n",
    "        train_corpus=nltk.word_tokenize(corpus)\n",
    "    else:\n",
    "        print('Error')\n",
    "        return None\n",
    "    \n",
    "    freq_dist=None\n",
    "    if ngram==1:\n",
    "        freq_dist = nltk.FreqDist(train_corpus) #freq distibution for unigrams\n",
    "    elif ngram==2:\n",
    "        freq_dist = nltk.ConditionalFreqDist(nltk.ngrams(train_corpus, 2))# conditional freq dist for bigrams\n",
    "    elif ngram==3:\n",
    "        trigrams_as_bigrams=[]\n",
    "        trigram =[a for a in ngrams(train_corpus, 3)]\n",
    "        trigrams_as_bigrams.extend([((t[0],t[1]), t[2]) for t in trigram])\n",
    "        freq_dist = nltk.ConditionalFreqDist(trigrams_as_bigrams)# conditional freq dist for trigrams\n",
    "    else:\n",
    "        print('Supported upto trigrams only')\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_2gram = ngram_freq_dist(train_corpus, 2)\n",
    "# cfd_2gram_rev = ngram_freq_dist(rev_train_corpus, 2)\n",
    "\n",
    "cpd_2gram = nltk.ConditionalProbDist(cfd_2gram, nltk.MLEProbDist)\n",
    "# cpd_2gram_rev = nltk.ConditionalProbDist(cfd_2gram_rev, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_bigram_model_random(cprob_2gram, cprob_2gram_rev, initialword, numwords=15):\n",
    "    text = initialword\n",
    "    suf_word = initialword\n",
    "    pre_word = initialword\n",
    "    for index in range(numwords):\n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                suf_word = cprob_2gram[suf_word].generate()\n",
    "                text = text + \" \" + suf_word\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "        else:\n",
    "            try: \n",
    "                pre_word = cprob_2gram_rev[pre_word].generate()\n",
    "                text = pre_word + ' ' + text\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PRP'), ('is', 'VBZ'), ('coming', 'VBG'), ('here', 'RB')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['he', 'is', 'coming', 'here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_template_dict = {\n",
    "    'START': [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
    "    'NP': [['Det', 'NOM']],\n",
    "    'NOM': [['Noun', 'NOM']],\n",
    "    'VP': [['Verb'], ['Verb', 'NP']],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('citizens', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('election', 'NN'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('ride', 'VB'),\n",
       " ('away', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('politics', 'NNS'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('class', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sounded alike today congrats to serve should n't let celebrate education should be right to mark\n",
      "----------------------------------------\n",
      "//t.… seattle see this gmo labels on education equal pay gap he bankrupted his own employees\n",
      "----------------------------------------\n",
      "a racially biased practice according to be higher education not to close to the fda who\n",
      "----------------------------------------\n",
      "themselves w/o affecting their fair learn more affordable higher education we ’ ll build on the\n",
      "----------------------------------------\n",
      "most major country on fossil fuels in the education not adjourn w/o an excellent choice rt\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'education'))\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
