{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'corpus.txt'\n",
    "\n",
    "stopwords = ['', '(', ')', '{', '}', '\\\\', '--', ':', '-', \"'s\"]\n",
    "punc = string.punctuation + \"``\" + \"''\" + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r') as f:\n",
    "    data = f.read().lower().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3954021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(words)\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_rev_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(list(reversed(words)))\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenized_words(data)\n",
    "rev_sents = tokenized_rev_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [word for sent in sents for word in sent]\n",
    "rev_train_corpus = [word for sent in rev_sents for word in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_dist(corpus, ngram=1):\n",
    "    if isinstance(corpus, list) and len(corpus)>0:\n",
    "        train_corpus=corpus\n",
    "    elif type(corpus) is str:\n",
    "        train_corpus=nltk.word_tokenize(corpus)\n",
    "    else:\n",
    "        print('Error')\n",
    "        return None\n",
    "    \n",
    "    freq_dist=None\n",
    "    if ngram==1:\n",
    "        freq_dist = nltk.FreqDist(train_corpus) #freq distibution for unigrams\n",
    "    elif ngram==2:\n",
    "        freq_dist = nltk.ConditionalFreqDist(nltk.ngrams(train_corpus, 2))# conditional freq dist for bigrams\n",
    "    elif ngram==3:\n",
    "        trigrams_as_bigrams=[]\n",
    "        trigram =[a for a in ngrams(train_corpus, 3)]\n",
    "        trigrams_as_bigrams.extend([((t[0],t[1]), t[2]) for t in trigram])\n",
    "        freq_dist = nltk.ConditionalFreqDist(trigrams_as_bigrams)# conditional freq dist for trigrams\n",
    "    else:\n",
    "        print('Supported upto trigrams only')\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_2gram = ngram_freq_dist(train_corpus, 2)\n",
    "cfd_2gram_rev = ngram_freq_dist(rev_train_corpus, 2)\n",
    "\n",
    "cpd_2gram = nltk.ConditionalProbDist(cfd_2gram, nltk.MLEProbDist)\n",
    "cpd_2gram_rev = nltk.ConditionalProbDist(cfd_2gram_rev, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate random tweets\n",
    "\n",
    "def generate_txt_bigram_model_random(cprob_2gram, cprob_2gram_rev, initialword, numwords=15):\n",
    "    text = initialword\n",
    "    suf_word = initialword\n",
    "    pre_word = initialword\n",
    "    for index in range(numwords):\n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                suf_word = cprob_2gram[suf_word].generate()\n",
    "                text = text + \" \" + suf_word\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "        else:\n",
    "            try: \n",
    "                pre_word = cprob_2gram_rev[pre_word].generate()\n",
    "                text = pre_word + ' ' + text\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PRP'), ('is', 'VBZ'), ('coming', 'VBG'), ('here', 'RB')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['he', 'is', 'coming', 'here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('citizens', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('election', 'NN'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('ride', 'VB'),\n",
       " ('away', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('politics', 'NNS'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('class', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_template_dict = {\n",
    "    'V': [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
    "    'NP': [['Det', 'NOM']],\n",
    "    'NOM': [['Noun', 'NOM']],\n",
    "    'VP': [['Verb'], ['Verb', 'NP']],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = []\n",
    "random_pos_tags = []\n",
    "random_word_pos_tags = []\n",
    "\n",
    "# Generate 200 sentences randomly \n",
    "for _ in range(200):\n",
    "    sent = generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'election', 9)\n",
    "    word_pos_tags = nltk.pos_tag(sent.split())\n",
    "    pos_tags = [x[1] for x in word_pos_tags]\n",
    "    \n",
    "    random_word_pos_tags.append(word_pos_tags)\n",
    "    random_sentences.append(sent)\n",
    "    random_pos_tags.append(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop until election just over the federal funding bill to',\n",
       " 'clear fracking secretary general election is made a republican politicians',\n",
       " \"republicans ca today election cycle joseiswriting rt somersworthdems governor o'malley\",\n",
       " 'better than any election day should be it easier to',\n",
       " 'come and make this election the same instead she spent']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NN', 'IN', 'NN', 'RB', 'IN', 'DT', 'JJ', 'NN', 'NN', 'TO'],\n",
       " ['JJ', 'NN', 'NN', 'JJ', 'NN', 'VBZ', 'VBN', 'DT', 'JJ', 'NNS'],\n",
       " ['NNS', 'MD', 'NN', 'NN', 'NN', 'VBG', 'JJ', 'NNS', 'VBP', 'NN'],\n",
       " ['RBR', 'IN', 'DT', 'NN', 'NN', 'MD', 'VB', 'PRP', 'JJR', 'TO'],\n",
       " ['NN', 'CC', 'VB', 'DT', 'NN', 'DT', 'JJ', 'RB', 'PRP', 'VBD']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pos_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('stop', 'NN'),\n",
       "  ('until', 'IN'),\n",
       "  ('election', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('over', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('federal', 'JJ'),\n",
       "  ('funding', 'NN'),\n",
       "  ('bill', 'NN'),\n",
       "  ('to', 'TO')],\n",
       " [('clear', 'JJ'),\n",
       "  ('fracking', 'NN'),\n",
       "  ('secretary', 'NN'),\n",
       "  ('general', 'JJ'),\n",
       "  ('election', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('made', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('republican', 'JJ'),\n",
       "  ('politicians', 'NNS')],\n",
       " [('republicans', 'NNS'),\n",
       "  ('ca', 'MD'),\n",
       "  ('today', 'NN'),\n",
       "  ('election', 'NN'),\n",
       "  ('cycle', 'NN'),\n",
       "  ('joseiswriting', 'VBG'),\n",
       "  ('rt', 'JJ'),\n",
       "  ('somersworthdems', 'NNS'),\n",
       "  ('governor', 'VBP'),\n",
       "  (\"o'malley\", 'NN')],\n",
       " [('better', 'RBR'),\n",
       "  ('than', 'IN'),\n",
       "  ('any', 'DT'),\n",
       "  ('election', 'NN'),\n",
       "  ('day', 'NN'),\n",
       "  ('should', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('easier', 'JJR'),\n",
       "  ('to', 'TO')],\n",
       " [('come', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('make', 'VB'),\n",
       "  ('this', 'DT'),\n",
       "  ('election', 'NN'),\n",
       "  ('the', 'DT'),\n",
       "  ('same', 'JJ'),\n",
       "  ('instead', 'RB'),\n",
       "  ('she', 'PRP'),\n",
       "  ('spent', 'VBD')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_word_pos_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sounded alike today congrats to serve should n't let celebrate education should be right to mark\n",
      "----------------------------------------\n",
      "//t.… seattle see this gmo labels on education equal pay gap he bankrupted his own employees\n",
      "----------------------------------------\n",
      "a racially biased practice according to be higher education not to close to the fda who\n",
      "----------------------------------------\n",
      "themselves w/o affecting their fair learn more affordable higher education we ’ ll build on the\n",
      "----------------------------------------\n",
      "most major country on fossil fuels in the education not adjourn w/o an excellent choice rt\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'education'))\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
